%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Adam Spencer at 2023-04-17 17:34:53 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@book{dynkin1960,
	author = {E. B. Dynkin},
	date-added = {2023-04-17 17:32:44 +0100},
	date-modified = {2023-04-17 17:34:13 +0100},
	editor = {T. K{\"o}v{\'a}ry},
	publisher = {Pergamon Press},
	title = {Theory of Markov Processes},
	year = {1960}}

@article{Rabiner1989Feb,
	author = {Rabiner, L. R.},
	date-added = {2023-04-17 16:52:16 +0100},
	date-modified = {2023-04-17 16:52:16 +0100},
	doi = {10.1109/5.18626},
	issn = {1558-2256},
	journal = {Proc. IEEE},
	month = feb,
	number = {2},
	pages = {257--286},
	publisher = {IEEE},
	title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
	urldate = {2023-04-17},
	volume = {77},
	year = {1989},
	bdsk-url-1 = {https://doi.org/10.1109/5.18626}}

@article{bengio1999markovian,
	author = {Bengio, Yoshua and others},
	date-added = {2023-04-14 14:59:24 +0100},
	date-modified = {2023-04-14 14:59:24 +0100},
	journal = {Neural computing surveys},
	number = {199},
	pages = {129--162},
	title = {Markovian models for sequential data},
	volume = {2},
	year = {1999}}

@inproceedings{hmm2023,
	abstract = {In order to use hidden Markov model to realize power dispatch speech recognition and improve the accuracy of recognition results, this paper will carry out relevant research. The paper first introduces the hidden Markov model, then builds a speech recognition system based on the model, and finally tests the system with an example. Through the research, the hidden Markov model has good application value in power dispatching speech recognition, driven by the model, the accuracy of recognition results has been significantly improved, and is very stable.},
	address = {Cham},
	author = {Dong, Xiaoling and Cao, Wanwan and Cheng, Hang and Zhang, Tianqi},
	booktitle = {Tenth International Conference on Applications and Techniques in Cyber Intelligence (ICATCI 2022)},
	date-added = {2023-04-14 14:50:07 +0100},
	date-modified = {2023-04-14 14:50:16 +0100},
	editor = {Abawajy, Jemal H. and Xu, Zheng and Atiquzzaman, Mohammed and Zhang, Xiaolu},
	isbn = {978-3-031-29097-8},
	pages = {760--768},
	publisher = {Springer International Publishing},
	title = {Hidden Markov Model-Driven Speech Recognition for Power Dispatch},
	year = {2023}}

@book{baker1975stochastic,
	author = {Baker, James K},
	date-added = {2023-04-14 14:38:38 +0100},
	date-modified = {2023-04-14 14:38:38 +0100},
	publisher = {Carnegie Mellon University},
	title = {Stochastic modeling as a means of automatic speech recognition.},
	year = {1975}}

@article{chime6,
	author = {Shinji Watanabe and Michael I. Mandel and Jon Barker and Emmanuel Vincent},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2004-09249.bib},
	date-added = {2023-04-12 17:06:43 +0100},
	date-modified = {2023-04-12 17:06:47 +0100},
	eprint = {2004.09249},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Fri, 18 Sep 2020 07:54:42 +0200},
	title = {CHiME-6 Challenge: Tackling Multispeaker Speech Recognition for Unsegmented Recordings},
	url = {https://arxiv.org/abs/2004.09249},
	volume = {abs/2004.09249},
	year = {2020},
	bdsk-url-1 = {https://arxiv.org/abs/2004.09249}}

@inproceedings{wav2vec2,
	author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2023-04-12 16:45:38 +0100},
	date-modified = {2023-04-12 16:45:55 +0100},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	pages = {12449--12460},
	publisher = {Curran Associates, Inc.},
	title = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
	url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf},
	volume = {33},
	year = {2020},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf}}

@article{LevinsonS.E.1983Aitt,
	abstract = {In this paper we present several of the salient theoretical and practical issues associated with modeling a speech signal as a probabilistic function of a (hidden) Markov chain. First we give a concise review of the literature with emphasis on the Baum-Welch algorithm. This is followed by a detailed discussion of three issues not treated in the literature: alternatives to the Baum-Welch algorithm; critical facets of the implementation of the algorithms, with emphasis on their numerical properties; and behavior of Markov models on certain artificial but realistic problems. Special attention is given to a particular class of Markov models, which we call "left-to-right" models. This class of models is especially appropriate for isolated word recognition. The results of the application of these methods to an isolated word, speaker-independent speech recognition experiment are given in a companion paper.},
	address = {Oxford, UK},
	author = {Levinson, S. E. and Rabiner, L. R. and Sondhi, M. M.},
	copyright = {1983 The Bell System Technical Journal},
	date-added = {2023-04-12 16:39:17 +0100},
	date-modified = {2023-04-12 16:39:17 +0100},
	edition = {Manuscript received September 10, 1982},
	issn = {0005-8580},
	journal = {Bell System Technical Journal},
	keywords = {Applied sciences ; Artificial intelligence ; Computer science; control theory; systems ; Exact sciences and technology ; Speech and sound recognition and synthesis. Linguistics},
	language = {eng},
	number = {4},
	pages = {1035--1074},
	publisher = {American Telephone and Telegraph Company},
	title = {An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition},
	volume = {62},
	year = {1983}}

@article{asr-52,
	author = {Davis,K. H. and Biddulph,R. and Balashek,S.},
	date-added = {2023-04-12 16:10:49 +0100},
	date-modified = {2023-04-12 16:10:57 +0100},
	doi = {10.1121/1.1906946},
	eprint = {https://doi.org/10.1121/1.1906946},
	journal = {The Journal of the Acoustical Society of America},
	number = {6},
	pages = {637-642},
	title = {Automatic Recognition of Spoken Digits},
	url = {https://doi.org/10.1121/1.1906946},
	volume = {24},
	year = {1952},
	bdsk-url-1 = {https://doi.org/10.1121/1.1906946}}

@article{vocoder,
	author = {DUDLEY W. H.},
	date-added = {2023-04-12 16:08:33 +0100},
	date-modified = {2023-04-12 16:08:37 +0100},
	journal = {Bell. Labs. Rec.},
	pages = {122},
	title = {The vocoder},
	url = {https://cir.nii.ac.jp/crid/1572261551231523968},
	volume = {18},
	year = {1939},
	bdsk-url-1 = {https://cir.nii.ac.jp/crid/1572261551231523968}}

@article{Rabiner2004Jan,
	author = {Rabiner, Lawrence R.},
	date-added = {2023-04-12 15:31:31 +0100},
	date-modified = {2023-04-12 15:31:31 +0100},
	journal = {Scinapse},
	month = jan,
	title = {{Automatic Speech Recognition - A Brief History of the Technology Development}},
	url = {https://www.scinapse.io/papers/187290754},
	urldate = {2023-04-12},
	year = {2004},
	bdsk-url-1 = {https://www.scinapse.io/papers/187290754}}

@article{early-asr,
	author = {Jelinek, F.},
	date-added = {2023-04-12 15:24:33 +0100},
	date-modified = {2023-04-12 15:24:38 +0100},
	doi = {10.1109/PROC.1976.10159},
	journal = {Proceedings of the IEEE},
	number = {4},
	pages = {532-556},
	title = {Continuous speech recognition by statistical methods},
	volume = {64},
	year = {1976},
	bdsk-url-1 = {https://doi.org/10.1109/PROC.1976.10159}}

@book{YuDong2015Asre,
	address = {London},
	author = {Yu, Dong and Deng, Li},
	date-added = {2023-04-12 14:00:57 +0100},
	date-modified = {2023-04-12 14:00:57 +0100},
	isbn = {9781447157793},
	keywords = {Automatic speech recognition; Pattern recognition systems; Perceptrons; Speech Intelligibility of; Speech perception; Speech processing systems; Electronic books},
	language = {eng},
	publisher = {Springer},
	series = {Signals and communication technology},
	title = {Automatic speech recognition [electronic resource] : a deep learning approach},
	year = {2015}}

@misc{pypi-whis,
	date-added = {2023-04-10 15:40:07 +0100},
	date-modified = {2023-04-10 15:40:15 +0100},
	journal = {PyPI},
	month = apr,
	note = {[Online; accessed 10. Apr. 2023]},
	title = {{openai-whisper}},
	url = {https://pypi.org/project/openai-whisper},
	urldate = {2023-04-10},
	year = {2023},
	bdsk-url-1 = {https://pypi.org/project/openai-whisper}}

@article{numpy,
	author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, St{\'e} fan J and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and Fern{\'a}ndez del R{\'\i}o, Jaime and Wiebe, Mark and Peterson, Pearu and G{\'e}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	date-added = {2023-04-08 17:46:40 +0100},
	date-modified = {2023-04-08 17:46:45 +0100},
	doi = {10.1038/s41586-020-2649-2},
	journal = {Nature},
	pages = {357--362},
	title = {Array programming with {NumPy}},
	volume = {585},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1038/s41586-020-2649-2}}

@misc{pysoundfile,
	author = {Bastian Bechtold},
	date-added = {2023-04-08 17:40:40 +0100},
	date-modified = {2023-04-08 17:41:10 +0100},
	journal = {GitHub},
	note = {[Online; accessed 8. Apr. 2023]},
	title = {{python-soundfile}},
	url = {https://github.com/bastibe/python-soundfile},
	urldate = {2023-04-08},
	year = {2013},
	bdsk-url-1 = {https://github.com/bastibe/python-soundfile}}

@misc{textgridpy,
	author = {Kyle Gorman},
	date-added = {2023-04-08 16:54:31 +0100},
	date-modified = {2023-04-08 16:55:38 +0100},
	journal = {GitHub},
	month = apr,
	note = {[Online; accessed 8. Apr. 2023]},
	title = {textgrid.py},
	url = {http://github.com/kylebgorman/textgrid/},
	urldate = {2023-04-08},
	year = {2023},
	bdsk-url-1 = {https://github.com/kylebgorman/textgrid}}

@misc{praat,
	date-added = {2023-04-08 16:45:16 +0100},
	date-modified = {2023-04-08 16:45:22 +0100},
	month = mar,
	note = {[Online; accessed 8. Apr. 2023]},
	title = {{Praat: doing Phonetics by Computer}},
	url = {https://www.fon.hum.uva.nl/praat},
	urldate = {2023-04-08},
	year = {2023},
	bdsk-url-1 = {https://www.fon.hum.uva.nl/praat}}

@article{switchboard-ldc,
	author = {Godfrey, John J. and Edward Holliman},
	date-added = {2023-01-10 20:12:21 +0000},
	date-modified = {2023-01-10 20:43:46 +0000},
	journal = {Philadelphia: Linguistic Data Consortium},
	title = {Switchboard-1 Release 2 LDC97S62},
	year = {1993}}

@article{macrophone,
	author = {Bernstein, Jared and Kelsey Taussig and Jack Godfrey},
	date-added = {2023-01-10 20:08:52 +0000},
	date-modified = {2023-01-10 20:44:20 +0000},
	journal = {Philadelphia: Linguistic Data Consortium},
	title = {MACROPHONE LDC94S21},
	year = {1994}}

@article{baba2004,
	abstract = {Abstract Widespread use of large-vocabulary continuous speech
	            recognition systems has recently occurred, encouraging the
	            application of speech recognition techniques to various problems.
	            One of the factors that adversely affect the performance of speech
	            recognition systems is a mismatch between the acoustic properties
	            of the speech of the system user and the acoustic model. The speech
	            of young or middle-aged adults is generally used in constructing
	            the acoustic model. Thus, a mismatch occurs between the model and
	            the acoustic properties of the speech of the elderly, which may
	            degrade the recognition rate. In this study, a large-scale elderly
	            speech database (200 sentences ×301 subjects) is used to train the
	            acoustic model, and the resulting elderly acoustic model is
	            evaluated by using a large-vocabulary continuous speech recognition
	            system. In the experiments, the word recognition rate was improved
	            by 3 to 5\% compared to the recognition results of an acoustic
	            model trained by young or middle-aged adult speech, namely, by the
	            JNAS speech database (150 sentences ×260 subjects, average 28.6
	            years). It is also verified experimentally that the recognition
	            rate is further improved in speaker adaptation to elderly speech by
	            making use of an acoustic model trained by elderly speech. {
	            \copyright} 2004 Wiley Periodicals, Inc. Electron Comm Jpn Pt 2,
	            87(7): 49--57, 2004; Published online in Wiley InterScience
	            (www.interscience.wiley.com). DOI 10.1002/ecjb.20101},
	author = {Baba, Akira and Yoshizawa, Shinichi and Yamada, Miichi and Lee, Akinobu and Shikano, Kiyohiro},
	date-added = {2023-01-10 14:44:10 +0000},
	date-modified = {2023-01-10 14:44:19 +0000},
	doi = {https://doi.org/10.1002/ecjb.20101},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ecjb.20101},
	journal = {Electronics and Communications in Japan (Part II: Electronics)},
	keywords = {elderly, large-vocabulary continuous speech recognition, acoustic model, speaker adaptation},
	number = {7},
	pages = {49-57},
	title = {Acoustic models of the elderly for large-vocabulary continuous speech recognition},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ecjb.20101},
	volume = {87},
	year = {2004},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ecjb.20101},
	bdsk-url-2 = {https://doi.org/10.1002/ecjb.20101}}

@article{Georgila2010Sep,
	author = {Georgila, Kallirroi and Wolters, Maria and Moore, Johanna D. and Logie, Robert H.},
	date-added = {2023-01-10 14:33:11 +0000},
	date-modified = {2023-01-10 14:33:11 +0000},
	doi = {10.1007/s10579-010-9118-8},
	issn = {1574-0218},
	journal = {Lang. Resources {\&}. Evaluation},
	month = sep,
	number = {3},
	pages = {221--261},
	publisher = {Springer Netherlands},
	title = {{The MATCH corpus: a corpus of older and younger users{'} interactions with spoken dialogue systems}},
	volume = {44},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1007/s10579-010-9118-8}}

@inproceedings{fang2020,
	abstract = {Even though Automatic Speech Recognition (ASR) systems
	            significantly improved over the last decade, they still introduce a
	            lot of errors when they transcribe voice to text. One of the most
	            common reasons for these errors is phonetic confusion between
	            similar-sounding expressions. As a result, ASR transcriptions often
	            contain "quasi-oronyms", i.e., words or phrases that sound similar
	            to the source ones, but that have completely different semantics
	            (e.g., "win" instead of "when" or "accessible on defecting" instead
	            of "accessible and affecting"). These errors significantly affect
	            the performance of downstream Natural Language Understanding (NLU)
	            models (e.g., intent classification, slot filling, etc.) and impair
	            user experience. To make NLU models more robust to such errors, we
	            propose novel phonetic-aware text representations. Specifically, we
	            represent ASR transcriptions at the phoneme level, aiming to
	            capture pronunciation similarities, which are typically neglected
	            in word-level representations (e.g., word embeddings). To train and
	            evaluate our phoneme representations, we generate noisy ASR
	            transcriptions of four existing datasets - Stanford Sentiment
	            Treebank, SQuAD, TREC Question Classification and Subjectivity
	            Analysis - and show that common neural network architectures
	            exploiting the proposed phoneme representations can effectively
	            handle noisy transcriptions and significantly outperform
	            state-of-the-art baselines. Finally, we confirm these results by
	            testing our models on real utterances spoken to the Alexa virtual
	            assistant.},
	address = {New York, NY, USA},
	author = {Fang, Anjie and Filice, Simone and Limsopatham, Nut and Rokhlenko, Oleg},
	booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	date-added = {2023-01-09 15:15:07 +0000},
	date-modified = {2023-01-09 15:15:17 +0000},
	doi = {10.1145/3397271.3401050},
	isbn = {9781450380164},
	keywords = {virtual assistant, phoneme embeddings, classification, natural language understanding, ASR error, deep learning},
	location = {Virtual Event, China},
	numpages = {10},
	pages = {699--708},
	publisher = {Association for Computing Machinery},
	series = {SIGIR '20},
	title = {Using Phoneme Representations to Build Predictive Models Robust to ASR Errors},
	url = {https://doi.org/10.1145/3397271.3401050},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1145/3397271.3401050}}

@article{Taylor2020Mar,
	author = {Taylor, Sammi and Dromey, Christopher and Nissen, Shawn L. and Tanner, Kristine and Eggett, Dennis and Corbin-Lewis, Kim},
	date-added = {2023-01-09 14:30:10 +0000},
	date-modified = {2023-01-09 14:30:10 +0000},
	doi = {10.1044/2019_JSLHR-19-00028},
	journal = {Journal of Speech, Language, and Hearing Research : JSLHR},
	month = mar,
	number = {3},
	pages = {647},
	publisher = {American Speech-Language-Hearing Association},
	title = {{Age-Related Changes in Speech and Voice: Spectral and Cepstral Measures}},
	volume = {63},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1044/2019_JSLHR-19-00028}}

@article{richards_1987,
	author = {Richards, Brian},
	date-added = {2023-01-09 13:51:55 +0000},
	date-modified = {2023-01-09 13:51:55 +0000},
	doi = {10.1017/S0305000900012885},
	journal = {Journal of Child Language},
	number = {2},
	pages = {201--209},
	publisher = {Cambridge University Press},
	title = {Type/Token Ratios: what do they really tell us?},
	volume = {14},
	year = {1987},
	bdsk-url-1 = {https://doi.org/10.1017/S0305000900012885}}

@article{huggingfacetransformers,
	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Perric and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
	date-added = {2023-01-08 16:45:42 +0000},
	date-modified = {2023-01-10 20:43:14 +0000},
	journal = {Association for Computational Linguistics},
	month = {10},
	pages = {38--45},
	title = {{Transformers: State-of-the-Art Natural Language Processing}},
	url = {https://www.aclweb.org/anthology/2020.emnlp-demos.6},
	year = {2020},
	bdsk-url-1 = {https://www.aclweb.org/anthology/2020.emnlp-demos.6}}

@book{nltk,
	author = {Bird, Steven and Klein, Ewan and Loper, Edward},
	date-added = {2023-01-08 16:33:55 +0000},
	date-modified = {2023-01-08 16:34:01 +0000},
	publisher = {O'Reilly Media, Inc.},
	title = {{Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit}},
	year = {2009}}

@article{gaikwad2010review,
	author = {Gaikwad, Santosh K and Gawali, Bharti W and Yannawar, Pravin},
	date-added = {2023-01-08 15:44:21 +0000},
	date-modified = {2023-01-08 15:44:21 +0000},
	journal = {International Journal of Computer Applications},
	number = {3},
	pages = {16--24},
	publisher = {International Journal of Computer Applications, 244 5 th Avenue, \# 1526, New~{\ldots}},
	title = {A review on speech recognition technique},
	volume = {10},
	year = {2010}}

@article{Maclay1959Jan,
	author = {Maclay, Howard and Osgood, Charles E.},
	date-added = {2023-01-06 17:30:55 +0000},
	date-modified = {2023-01-06 17:31:06 +0000},
	doi = {10.1080/00437956.1959.11659682},
	issn = {0043-7956},
	journal = {WORD},
	month = jan,
	number = {1},
	pages = {19--44},
	publisher = {Routledge},
	title = {{Hesitation Phenomena in Spontaneous English Speech}},
	volume = {15},
	year = {1959},
	bdsk-url-1 = {https://doi.org/10.1080/00437956.1959.11659682}}

@misc{whisper,
	author = {Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
	date-added = {2023-01-04 16:05:40 +0000},
	date-modified = {2023-01-04 16:09:16 +0000},
	howpublished = {arXiv:2212.04356},
	title = {Robust Speech Recognition via Large-Scale Weak Supervision},
	year = {2022}}

@misc{zhang2020,
	author = {Yu Zhang and James Qin and Daniel S. Park and Wei Han and Chung-Cheng Chiu and Ruoming Pang and Quoc V. Le and Yonghui Wu},
	date-added = {2023-01-04 16:03:34 +0000},
	date-modified = {2023-01-04 16:05:15 +0000},
	eprint = {arXiv:2010.10504},
	title = {Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition},
	year = {2020}}

@misc{vote400,
	author = {Jang, Minsu and Seo, Sangwon and Kim, Dohyung and Lee, Jaeyeon and Kim, Jaehong and Ahn, Jun-Hwan},
	copyright = {Creative Commons Attribution 4.0 International},
	date-added = {2023-01-02 21:33:52 +0000},
	date-modified = {2023-01-02 21:33:57 +0000},
	doi = {10.48550/ARXIV.2101.11469},
	keywords = {Audio and Speech Processing (eess.AS), Computation and Language (cs.CL), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {VOTE400(Voide Of The Elderly 400 Hours): A Speech Dataset to Study Voice Interface for Elderly-Care},
	url = {https://arxiv.org/abs/2101.11469},
	year = {2021},
	bdsk-url-1 = {https://arxiv.org/abs/2101.11469},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2101.11469}}

@article{bigssl,
	author = {Yu Zhang and Daniel S. Park and Wei Han and James Qin and Anmol Gulati and Joel Shor and Aren Jansen and Yuanzhong Xu and Yanping Huang and Shibo Wang and Zongwei Zhou and Bo Li and Min Ma and William Chan and Jiahui Yu and Yongqiang Wang and Liangliang Cao and Khe Chai Sim and Bhuvana Ramabhadran and Tara N. Sainath and Francoise Beaufays and Zhifeng Chen and Quoc V. Le and Chung-Cheng Chiu and Ruoming Pang and Yonghui Wu},
	date-added = {2023-01-02 18:30:04 +0000},
	date-modified = {2023-01-02 18:30:04 +0000},
	doi = {10.1109/jstsp.2022.3182537},
	journal = {{IEEE} Journal of Selected Topics in Signal Processing},
	month = {oct},
	number = {6},
	pages = {1519--1532},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	title = {{BigSSL}: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition},
	url = {https://doi.org/10.1109%2Fjstsp.2022.3182537},
	volume = {16},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109%2Fjstsp.2022.3182537},
	bdsk-url-2 = {https://doi.org/10.1109/jstsp.2022.3182537}}

@misc{chung2021,
	author = {Chung, Yu-An and Zhang, Yu and Han, Wei and Chiu, Chung-Cheng and Qin, James and Pang, Ruoming and Wu, Yonghui},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2023-01-02 18:14:26 +0000},
	date-modified = {2023-01-02 18:14:38 +0000},
	doi = {10.48550/ARXIV.2108.06209},
	keywords = {Machine Learning (cs.LG), Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
	publisher = {arXiv},
	title = {W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training},
	url = {https://arxiv.org/abs/2108.06209},
	year = {2021},
	bdsk-url-1 = {https://arxiv.org/abs/2108.06209},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2108.06209}}

@inproceedings{librispeech,
	author = {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
	booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	date-added = {2023-01-02 17:25:45 +0000},
	date-modified = {2023-01-02 17:25:50 +0000},
	doi = {10.1109/ICASSP.2015.7178964},
	pages = {5206-5210},
	title = {Librispeech: An ASR corpus based on public domain audio books},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP.2015.7178964}}

@inproceedings{picone1990,
	author = {Picone, J.},
	booktitle = {International Conference on Acoustics, Speech, and Signal Processing},
	date-added = {2023-01-02 16:22:23 +0000},
	date-modified = {2023-01-02 16:22:33 +0000},
	doi = {10.1109/ICASSP.1990.115549},
	pages = {105-108 vol.1},
	title = {The demographics of speaker independent digit recognition},
	year = {1990},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP.1990.115549}}

@inproceedings{switchboard,
	author = {Godfrey, J.J. and Holliman, E.C. and McDaniel, J.},
	booktitle = {[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing},
	date-added = {2023-01-01 19:23:36 +0000},
	date-modified = {2023-01-01 19:23:44 +0000},
	doi = {10.1109/ICASSP.1992.225858},
	pages = {517-520 vol.1},
	title = {SWITCHBOARD: telephone speech corpus for research and development},
	volume = {1},
	year = {1992},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP.1992.225858}}

@inproceedings{Ng2021,
	author = {Edwin G. Ng and Chung-Cheng Chiu and Yu Zhang and William Chan},
	booktitle = {Interspeech 2021},
	date-added = {2023-01-01 19:17:43 +0000},
	date-modified = {2023-01-01 19:18:16 +0000},
	doi = {10.21437/interspeech.2021-337},
	month = {aug},
	publisher = {ISCA},
	title = {Pushing the Limits of Non-Autoregressive Speech Recognition},
	url = {https://doi.org/10.21437%2Finterspeech.2021-337},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.21437%2Finterspeech.2021-337},
	bdsk-url-2 = {https://doi.org/10.21437/interspeech.2021-337}}

@inproceedings{seide2011,
	author = {Seide, Frank and Li, Gang and Chen, Xie and Yu, Dong},
	booktitle = {2011 IEEE Workshop on Automatic Speech Recognition & Understanding},
	date-added = {2023-01-01 19:01:53 +0000},
	date-modified = {2023-01-01 19:02:08 +0000},
	doi = {10.1109/ASRU.2011.6163899},
	pages = {24-29},
	title = {Feature engineering in Context-Dependent Deep Neural Networks for conversational speech transcription},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1109/ASRU.2011.6163899}}

@article{lifelucid,
	author = {Tuomainen, Outi and Taschenberger, Linda and Hazan, Valerie},
	date-added = {2022-12-29 17:49:25 +0000},
	date-modified = {2022-12-29 17:49:41 +0000},
	journal = {UK Data Service},
	month = may,
	publisher = {UK Data Service},
	title = {{LifeLUCID Corpus: Recordings of Speakers Aged 8 to 85 Years Engaged in Interactive Task in the Presence of Energetic and Informational Masking, 2017-2020}},
	url = {https://reshare.ukdataservice.ac.uk/854350},
	year = {2021},
	bdsk-url-1 = {https://reshare.ukdataservice.ac.uk/854350}}

@article{Horton2010,
	author = {Horton, William S. and Spieler, Daniel H. and Shriberg, Elizabeth},
	date-added = {2022-11-21 15:46:27 +0000},
	date-modified = {2022-11-21 15:46:27 +0000},
	doi = {10.1037/a0019424},
	issn = {1939-1498},
	journal = {Psychol. Aging},
	number = {3},
	pages = {708},
	publisher = {US: American Psychological Association},
	title = {{A corpus analysis of patterns of age-related change in conversational speech.}},
	volume = {25},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1037/a0019424}}

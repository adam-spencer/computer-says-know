\chapter{Literature Survey}\label{ch:literature-survey}

\section{Understanding Transcription}\label{sec:transcription}

\subsection{Manual Transcription}\label{subsec:manual-transcription}

\subsection{Semi-Automatic Transcription}\label{subsec:semi-auto-transcription}

\subsection{Fully-Automatic Transcription}\label{subsec:full-auto-transcription}


\section{Automatic Speech Recognition}\label{sec:what-is-asr}

\subsection{What is ASR?}

Automatic Speech Recognition (ASR) is a technology which allows computers to recognise and produce a text transcription of spoken language.
The research and development of ASR has been a part of computer science since the late 1930s\cite{Rabiner2004Jan,vocoder}, with rudimentary systems being constructed as early as the 1950s\cite{asr-52}.
These early attempts at recognising human speech treated it as a `pattern recognition' problem, the theory being that words could be constructed by recognising the pattern created in a speech signal as a set of spoken phonemes\cite{Rabiner2004Jan}. 
This paradigm falls apart when the system must be re-tuned for each individual, even for simple tasks such as recognising spoken digits\cite{asr-52}.

Since the 1970s, the problem of speech recognition has viewed more as one to be solved using statistical methods\cite{early-asr,Rabiner2004Jan,LevinsonS.E.1983Aitt}, with todays cutting-edge systems using Convolutional Neural Networks (CNNs)\cite{whisper,wav2vec2,bigssl,chung2021}, a method which requires massive quantities of data and computing power.
Today, speech recognition systems are ubiquitous in everyday computing tasks; 
integrated into operating systems and search engines, with uses ranging from `virtual assistants' (e.g., Apple's Siri, Amazon's Alexa) to providing people with disabilities the means to operate computer systems.

\subsection{Problems in Modern ASR}

Despite their ubiquity, modern ASR systems aren't without fault.
Cutting edge systems like \emph(wav2vec) are capable of achieving greater-than-human scores on specific datasets\cite{wav2vec2,bigssl,chung2021} such as \emph{LibriSpeech}\cite{librispeech}, achieving as low as 1.4\% error\cite{zhang2020}.
\mycomment{talk about supervised/unsupervised}
A major problem with comes when the data is not `clean', for example, background noise is present, microphones are far away, the speaker has an atypical speech pattern, etc. 
In this setting, \emph{wav2vec} achieves much poorer scores with word error rates as high as 65\%\cite{whisper} on the \emph{CHiME6} corpus\cite{chime6}.

\subsection{Whisper}

In late September 2022, the OpenAI research laboratory (known for such projects as GPT-3/4 and ChatGPT) released a new open-source ASR system known as `Whisper'~\cite{whisper}.
Whisper is unique in being very large (trained on 680,000 hours of speech data), open-source, and fully supervised;
all the training data used to create the model has been accurately labeled and
quality-checked by humans, unlike the much larger unsupervised `BigSSL' model (1,000,000+ hours of data)~\cite{bigssl}.

Whisper uses a natural language model to perform next-token prediction (in layperson's terms, there is a secondary system trying to ensure the intelligibility of sentences produced from transcription).
In a practical setting this means that conversational speech (i.e.\ speech which flows as sentences rather than semantically-disjoint terms) should be transcribed with a higher degree of accuracy.

\subsection{ASR Confidence}

\section{Speech Corpora}\label{sec:} \mycomment{Should this be before or after the section on modern ASR? Seems to me that it builds an understanding necessary for grasping ASR}

\section{Modern ASR}\label{sec:modern-asr}

\mycomment{Should write something about the state of modern ASR here...}

\section{Collection of Example Data}\label{sec:}
\section{}\label{sec:}
\section{}\label{sec:}
\section{}\label{sec:}

\section{Summary}\label{sec:lit-survey-summary}


#!/usr/bin/env python
"""
normalise_text

Normalise the text output by Whisper.

Normalisation is done using `whisper.normalizer.EnglishTextNormalizer` and
removing hesitations as defined in `HESITATION_TOKENS`.
"""
import json
from argparse import ArgumentParser
from pathlib import Path

from whisper.normalizers import EnglishTextNormalizer

normaliser = EnglishTextNormalizer()

HESITATION_TOKENS = {
    'er', 'erm', 'ermm', 'um', 'umm', 'uhm', 'uhmm', 'uh', 'uhh', 'uhhh', 'ER',
    'ERM', 'ERMM', 'UM', 'UMM', 'UHM', 'UHMM', 'UH', 'UHH', 'UHHH'
}


def normalise_string(inp: str) -> str:
    """Remove hesitations and normalise a string"""
    inp_norm = normaliser(inp)
    to_return = ''
    for word in inp_norm.split():
        if word not in HESITATION_TOKENS:
            to_return += word + ' '
    return to_return.strip()


def handle_confidence(segments: dict) -> dict:
    """
    Handle the confidence scores output by `whisper_timestamped`.

    :param segments: `utterance['whisper']['segments']`
    :returns: Confidence segments to be added to output dict
    """
    words_list = []
    confidence_list = []
    total_utterance_confidence = 0.0
    for segment in segments:
        total_utterance_confidence += segment['confidence']
        for word in segment['words']:
            text = normalise_string(word['text'])
            if len(text) > 0:
                words_list.append(text)
                confidence_list.append(word['confidence'])
    words = ' '.join(words_list)
    avg_utt_confidence = total_utterance_confidence / len(segments)
    return {
        'words': words,
        'confidence_scores': confidence_list,
        'utterance_confidence': avg_utt_confidence,
    }


def normalise_file(file: Path, confidence_mode: bool) -> dict:
    """Load a whisper output file and normalise the text within"""
    with open(file) as f:
        data = json.load(f)
    for utterance in data.values():
        utterance['transcript'] = normalise_string(utterance['transcript'])
        utterance['whisper']['text'] = normalise_string(
            utterance['whisper']['text'])
        if confidence_mode and (segs := utterance['whisper'].get('segments')):
            utterance['confidence_scoring'] = handle_confidence(segs)
    return data


def write_to_output(file: Path, data: dict) -> None:
    """Write the normalised data to a JSON file as output"""
    with open(file, 'w') as f:
        json.dump(data, f, indent=2)


def main():
    parser = ArgumentParser()
    parser.add_argument('input', help='Input file or directory')
    parser.add_argument('output', help='Output directory')
    parser.add_argument('--confidence-scores', '-c', action='store_true',
                        help='Input contains confidence scores')
    args = parser.parse_args()

    input_path = Path(args.input)
    output_path = Path(args.output)
    output_path.mkdir(exist_ok=True)

    confidence_mode = args.confidence_scores

    if input_path.is_dir():
        for file in input_path.iterdir():
            if not (fname := file.name).endswith('.json'):
                continue
            data = normalise_file(file, confidence_mode)
            file_out = output_path / fname.replace('.json', '_norm.json')
            write_to_output(file_out, data)
    else:
        data = normalise_file(input_path, confidence_mode)
        file_out = output_path / input_path.name.replace('.json', '_norm.json')
        write_to_output(file_out, data)


if __name__ == "__main__":
    main()

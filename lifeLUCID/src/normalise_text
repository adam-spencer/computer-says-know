#!/usr/bin/env python
"""
normalise_text

Normalise the text output by Whisper.

Normalisation is done using `whisper.normalizer.EnglishTextNormalizer` and
removing hesitations as defined in `HESITATION_TOKENS`.
"""
import json
from argparse import ArgumentParser
from pathlib import Path

from whisper.normalizers import EnglishTextNormalizer

normaliser = EnglishTextNormalizer()

HESITATION_TOKENS = {
    'er', 'erm', 'ermm', 'um', 'umm', 'uhm', 'uhmm', 'uh', 'uhh', 'uhhh', 'ER',
    'ERM', 'ERMM', 'UM', 'UMM', 'UHM', 'UHMM', 'UH', 'UHH', 'UHHH'
}


def normalise_string(inp: str) -> str:
    """Remove hesitations and normalise a string"""
    inp_norm = map(normaliser, inp.split())
    to_return = []
    for token in inp_norm:
        if token in HESITATION_TOKENS:
            continue
        # This next step joins together tokens which have been normalised into
        # multiple words with an underscore, in order to facilitate mapping
        # confidence scores onto those words correctly
        elif len(post_norm_words := token.split()) > 1:
            to_return.append('_'.join(post_norm_words))
        else:
            to_return.append(token)
    return ' '.join(to_return)


def handle_confidence(segments: dict) -> dict:
    """
    Handle the confidence scores output by `whisper_timestamped`.

    :param segments: `utterance['whisper']['segments']`
    :returns: Confidence segments to be added to output dict
    """
    words_list = []
    confidence_list = []
    total_utterance_confidence = 0.0
    for segment in segments:
        if not (seg_conf := segment.get('confidence')):
            continue
        total_utterance_confidence += seg_conf
        for word in segment['words']:
            text = normalise_string(word['text'])
            if len(text) > 0:
                words_list.append(text)
                confidence_list.append(word['confidence'])
    words = ' '.join(words_list)
    avg_utt_confidence = total_utterance_confidence / len(segments)
    return {
        'words': words,
        'confidence_scores': confidence_list,
        'utterance_confidence': avg_utt_confidence,
    }


def normalise_file(file: Path, confidence_mode: bool) -> dict:
    """Load a whisper output file and normalise the text within"""
    with open(file) as f:
        data = json.load(f)
    for utterance in data.values():
        utterance['transcript'] = normalise_string(utterance['transcript'])
        utterance['whisper']['text'] = normalise_string(
            utterance['whisper']['text'])
        if confidence_mode and (segs := utterance['whisper'].get('segments')):
            utterance['confidence_scoring'] = handle_confidence(segs)
    return data


def write_to_output(file: Path, data: dict) -> None:
    """Write the normalised data to a JSON file as output"""
    with open(file, 'w') as f:
        json.dump(data, f, indent=2)


def main():
    parser = ArgumentParser()
    parser.add_argument('input', help='Input file or directory')
    parser.add_argument('output', help='Output directory')
    parser.add_argument('--confidence-scores', '-c', action='store_true',
                        help='Input contains confidence scores')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='Activate verbose output')
    args = parser.parse_args()

    input_path = Path(args.input)
    output_path = Path(args.output)
    output_path.mkdir(exist_ok=True)

    confidence_mode = args.confidence_scores
    verbose = args.verbose

    if input_path.is_dir():
        in_files = [f for f in input_path.iterdir()]
        n_files = len(in_files)
        for idx, file in enumerate(in_files):
            if verbose:
                print(f'Progress: {idx:3} / {n_files:3}', end='\r')
            if not (fname := file.name).endswith('.json'):
                continue
            data = normalise_file(file, confidence_mode)
            file_out = output_path / fname.replace('.json', '_norm.json')
            write_to_output(file_out, data)
    else:
        data = normalise_file(input_path, confidence_mode)
        file_out = output_path / input_path.name.replace('.json', '_norm.json')
        write_to_output(file_out, data)


if __name__ == "__main__":
    main()
